{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='color:SteelBlue'>P7 - Implémentez un modèle  de scoring (part 4)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Logo pret_a_depenser](https://user.oc-static.com/upload/2023/03/22/16794938722698_Data%20Scientist-P7-01-banner.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='background:white; color:black'>Sommaire</span>\n",
    "\n",
    "**Introduction**\n",
    "\n",
    "Importations des librairies<br>\n",
    "\n",
    "Chemins d'accès<br>\n",
    "\n",
    "Fonctions <br>\n",
    "\n",
    "**Fonction principale**\n",
    "\n",
    "**Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='background:blue'>Introduction</span>\n",
    "\n",
    "L'entreprise **\"Prêt à dépenser\"** souhaite mettre en œuvre un outil de “scoring crédit” pour calculer la probabilité qu’un client rembourse son crédit, puis classifie la demande en crédit accordé ou refusé. Elle souhaite donc développer un **algorithme de classification** en s’appuyant sur des sources de données variées (données comportementales, données provenant d'autres institutions financières, etc.).\n",
    "___\n",
    "**Missions**<br>\n",
    "1/ Construire un modèle de scoring qui donnera une prédiction sur la probabilité de faillite d'un client de façon automatique.\n",
    "\n",
    "2/ Analyser les features qui contribuent le plus au modèle, d’une manière générale (feature importance globale) et au niveau d’un client (feature importance locale), afin, dans un soucis de transparence, de permettre à un chargé d’études de mieux comprendre le score attribué par le modèle.\n",
    "\n",
    "3/ Mettre en production le modèle de scoring de prédiction à l’aide d’une API et réaliser une interface de test de cette API.\n",
    "\n",
    "4/ Mettre en oeuvre une approche globale MLOps de bout en bout, du tracking des expérimentations à l’analyse en production du data drift.\n",
    "___\n",
    "Ce notebook presente la 4ème partie concernant l'analyse du data drift."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='background:grey'>Importations des librairies utilisees dans ce notebook</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from evidently.report import Report\n",
    "from evidently.metric_preset import DataDriftPreset\n",
    "from evidently import ColumnMapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='background:grey'>Chemins d'accès</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin du répertoire racine\n",
    "ROOT_DIR = \"C:\\\\Users\\\\pierr\\\\VSC_Projects\\\\Projet7_OCR_DataScientist\"\n",
    "\n",
    "# Chemin du fichiers des données de reference (application_train)\n",
    "DATA_REF_PATH = os.path.join(\n",
    "    ROOT_DIR, \"data\", \"cleaned\", \"application_train_cleaned.csv\"\n",
    ")\n",
    "\n",
    "# Chemin du fichier des données nouvelles (application_test)\n",
    "DATA_NEW_PATH = os.path.join(\n",
    "    ROOT_DIR, \"data\", \"cleaned\", \"application_test_cleaned.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='background:grey'>Fonctions</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, drop_columns):\n",
    "    \"\"\"\n",
    "    Charge les données à partir d'un fichier CSV et supprime les colonnes\n",
    "    spécifiées.\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(path)\n",
    "    data.drop(columns=drop_columns, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categorical_columns(data):\n",
    "    \"\"\"\n",
    "    Récupère les colonnes catégorielles d'un DataFrame (col avec des valeurs\n",
    "    uniques de 0, 1 et NaN).\n",
    "    \"\"\"\n",
    "    categorical_col = [\n",
    "        col for col in data.columns\n",
    "        if set(data[col].unique()).issubset({0, 1, np.nan})\n",
    "    ]\n",
    "    return categorical_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numerical_columns(data, categorical_col):\n",
    "    \"\"\"\n",
    "    Récupère les colonnes numériques d'un DataFrame (toutes les colonnes sauf\n",
    "    les colonnes catégorielles).\n",
    "    \"\"\"\n",
    "    all_columns = set(data.columns)\n",
    "    numerical_columns = list(all_columns - set(categorical_col))\n",
    "    return numerical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_drift_report(\n",
    "    numerical_columns,\n",
    "    categorical_col,\n",
    "    threshold=0.05\n",
    "):\n",
    "    \"\"\"\n",
    "    Crée un rapport de data drift avec les colonnes numériques et \n",
    "    catégorielles.\n",
    "    \"\"\"\n",
    "    # Création du column mapping (selon cat et num)\n",
    "    column_mapping = ColumnMapping()\n",
    "    column_mapping.numerical_features = numerical_columns\n",
    "    column_mapping.categorical_features = categorical_col\n",
    "\n",
    "    # Création du rapport de data drift\n",
    "    data_drift_rapport = Report(\n",
    "        metrics=[DataDriftPreset(\n",
    "            num_stattest='ks',\n",
    "            cat_stattest='psi',\n",
    "            num_stattest_threshold=threshold,\n",
    "            cat_stattest_threshold=threshold\n",
    "        )]\n",
    "    )\n",
    "    return data_drift_rapport, column_mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='background:blue'>Fonction principale</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Fonction principale pour comparer les données de référence et les données\n",
    "    actuelles (analyse du data drift).\n",
    "    \"\"\"\n",
    "    # Chargement des données\n",
    "    drop_columns = [\"Unnamed: 0\", \"TARGET\", \"SK_ID_CURR\"]\n",
    "    data_ref = load_data(DATA_REF_PATH, drop_columns)\n",
    "    data_new = load_data(DATA_NEW_PATH, drop_columns)\n",
    "\n",
    "    # Isolement des noms des colonnes numériques et catégorielles\n",
    "    categorical_col = get_categorical_columns(data_ref)\n",
    "    numerical_columns = get_numerical_columns(data_ref, categorical_col)\n",
    "\n",
    "    # Vérification de la similarité des colonnes des 2 DataFrames\n",
    "    assert set(data_ref.columns) == set(data_new.columns)\n",
    "\n",
    "    # Création du rapport de data drift\n",
    "    start_time = time.time()\n",
    "    data_drift_rapport, column_mapping = create_data_drift_report(\n",
    "        numerical_columns,\n",
    "        categorical_col,\n",
    "        threshold=0.05\n",
    "    )\n",
    "\n",
    "    # Run du rapport\n",
    "    start_time = time.time()\n",
    "    data_drift_rapport.run(\n",
    "        reference_data=data_ref,\n",
    "        current_data=data_new,\n",
    "        column_mapping=column_mapping\n",
    "    )\n",
    "\n",
    "    # Sauvegarde du rapport\n",
    "    data_drift_rapport.save_html(os.path.join(\n",
    "        ROOT_DIR,\n",
    "        \"Berthe_Pierrick_5_Tableau_HTML_data_drift_evidently_022024.html\"\n",
    "    ))\n",
    "\n",
    "# =========== étape 5 : Exécution de la fonction principale ===============\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le rapport de data drift est stocké dans le fichier **Berthe_Pierrick_5_Tableau_HTML_data_drift_evidently_022024.html**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style='background:blue'>Conclusions</span>\n",
    "\n",
    "Le rapport indique que 99 des 348 colonnes des données nouvelles (application_test) soit 28,4% des colonnes présentent un data drift. Cela signifie qu'environ un quart des colonnes ont des distributions différentes entre les données d'entraînement et les données de test. Le reste des colonnes, soit les trois quart des colonnes affichent des distributions similaires. \n",
    "\n",
    "Nous pouvons donc conclure que le nouveau dataset ne présente pas de data drift puisque le seuil pour un data drift est qu'au moins la moitié (>50%) des colonnes du nouveau dataset doivent présenter une distribution différente de l'ancien dataset pour qu'un data drift soit constaté. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
